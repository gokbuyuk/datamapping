"""This code contains the main function of the repository: get_matching. 
This is used to get the matching between the source and target variables using the similarity between variable names, \
    variable categories, variable description, and variable data types.
    
    To use this function, the user needs to specify the following:
        1. fileprefix: The prefix for all files generated by this script
        2. source_data_desc_filepath: The path to the source data description file that contains the variable names, categories, descriptions, and data types
        3. input_variable_format: the list of variable names that corresponds to Variable name, Variable category, Variable description, Variable data type, in this order.
        4. target_data_desc_path: The path to the target data description file that contains the variable names, categories, descriptions, and data types
        5. output_data_path: The path to the output directory
        
    The following outputs are saved in the output directory:
        1. A csv file with the matching between the source and target variables using the source as the key
        2. A csv file with the matching between the source and target variables using the target as the key
        3. A json file with the matching dictionary between the source and target variables using the target as the key
    
    If ground truth is available, the following outputs are saved in the reports directory:
        4. A csv file with the matching report between the source and target variables using the source as the key (if ground truth is available)
        5. A csv file with the matching report between the source and target variables using the target as the key (if ground truth is available)    
"""

import os
import json
from list_similarity import *
# from similarity_functions import *
from icecream import ic
import pandas as pd
import unittest
from os.path import join, normpath
import pathlib
import re


def get_matching(source_data_desc_filepath, 
                input_variable_format, 
                fileprefix,
                target_data_desc_path,
                output_data_path = ''): 
    """This function is the main function to be used by API to get the matching between the source and target variables using the similarity between source variable names, \
        and target variable names. The ouptputs are saved in the output_data_path folder if provided.
        Requires the target_data_desc.csv file path to be specified

    Args:
        source_data_desc_filepath (str): path to the input source data description file.
        input_variable_format (list): the list of variable names that corresponds to \
            Variable name, Variable category, Variable description, Variable data type, in this order.
        fileprefix (str): the prefix for all files generated by this script
        target_data_desc_path (str, optional): path to the input target data description file. Defaults to os.path.join(RAW_DIR, "target_data_desc.csv").
        output_data_path (str, optional): path to the output directory. Defaults to None.

    Returns:
        dict: a dictionary with the following keys:\
            1. matching_dict: a dictionary with the matching between the source and target variables using the data element categories as keys\
                and a list of dictionaries for each target variable, its description and data type along with the matching source variables, their descriptions, and data types
            2. source_to_target_matching: a dataframe with the matching between the source and target variables using the source as the key
            3. target_to_source_matching: a dataframe with the matching between the source and target variables using the target as the key
    """    

    # Read in the data description files
    target_data_desc = pd.read_csv(target_data_desc_path, header=0)
    # if isinstance(source0_data_desc, str):
    source0_data_desc = pd.read_csv(source_data_desc_filepath, header=0)

    column_names =  ['Variable name', 'Variable category', 'Variable description', 'Variable data type']

    # Clean the column names and data types to make sure they are consistent (e.g. convert varchar2(250) to varchar2)
    source0_data_desc.rename(columns=dict(zip(input_variable_format, column_names)), inplace=True)
    target_data_desc.columns = column_names

    dataType_regex = re.compile(r'^([\w\s]+)')
    for df in [source0_data_desc, target_data_desc]:
        # Extract data type with vectorized str method
        df['Variable data type'] = df['Variable data type'].str.strip().str.extract(dataType_regex, expand=False)
        df['Variable category'] = df['Variable category'].str.strip()
        # Use object dtype and str.join to avoid slower pandas apply
        df['Variable info'] = df.agg('|'.join, axis=1)
        

    # Get the list of maathing dictionaries for each matching between the source and target variables
    target_cols = target_data_desc['Variable name'].unique()
    categories = target_data_desc['Variable category'].unique()
    categories = [category for category in categories if 'organization identifying field' not in category.lower()]

    matching_dict = list()
    for category in categories:
        mappings = list()
        datatypes = target_data_desc.loc[target_data_desc['Variable category'] == category, 'Variable data type'].unique()
        # ic(datatypes)
        for datatype in datatypes:
            target_info_filtered = target_data_desc[
                (target_data_desc['Variable category'].str.lower() == category.lower())&(target_data_desc['Variable data type'].str.lower()==datatype.lower())
                ]['Variable info'].tolist()
            source_info_filtered = source0_data_desc[
                (source0_data_desc['Variable category'].str.lower() == category.lower())&(source0_data_desc['Variable data type'].str.lower()==datatype.lower())
                ]['Variable info'].tolist()
            # ic(category, datatype, target_info_filtered, source_info_filtered)
            ## if source doesn't have any variable in the filtered, return empyt dictionary for mappings
            if min(len(target_info_filtered), len(source_info_filtered)) == 0:
                mappings.append({})
            else:
                category_similarity_matrix = create_similarity_matrix(target_info_filtered, 
                                                                    source_info_filtered)
                # ic(category, category_similarity_matrix)

                # Find the index of the column with the highest score for each row
                # Check if the matrix is empty
                try:
                    row_max_indices = np.argmax(category_similarity_matrix, axis=1).tolist()
                    col_max_indices = np.argmax(category_similarity_matrix, axis=0).tolist()
                except ValueError:
                    continue


                ## TODO: This nested for loop can be optimizated
                for target_idx, target_info in enumerate(target_info_filtered):
                    target_col = target_info.split('|')[0]
                    target_desc = target_data_desc.loc[target_data_desc['Variable name'] == target_col, 'Variable description'].values[0]
                    target_dtype = target_data_desc.loc[target_data_desc['Variable name'] == target_col, 'Variable data type'].values[0]
                    
                    matches = list()
                    source_idx1 = row_max_indices[target_idx]
                    matches.append(source_info_filtered[source_idx1].split('|')[0])
                    if target_idx in col_max_indices:
                        source_idx2 = col_max_indices.index(target_idx)
                        matches.append(source_info_filtered[source_idx2].split('|')[0])
                    # ic(source_idx1, source_idx2, matches)
                    
                    source_cols = set(matches)
                    
                    for source_col in source_cols:  
                        row_similarities = category_similarity_matrix[target_idx]
                        # ic(row_similarities)
                        most_similar_columns = np.argsort(row_similarities)[::-1].tolist()
                        # ic(most_similar_columns)
                        most_similar_column_names = [source_info_filtered[idx].split('|')[0] for idx in most_similar_columns]
                        most_similar_column_names.remove(source_col)
                        most_similar_column_names.insert(0, source_col)
                        # ic(most_similar_column_names)
                        source_ele_desc = [source0_data_desc[source0_data_desc['Variable name'] == source_col]['Variable description'].tolist()[0] \
                                for source_col in most_similar_column_names]                
                        source_ele_dtype = [source0_data_desc[source0_data_desc['Variable name'] == source_col]['Variable data type'].tolist()[0] \
                                for source_col in most_similar_column_names]
                        # ic(target_col, most_similar_column_names, source_ele_desc, source_ele_dtype)
                        assert len(most_similar_column_names) == len(source_ele_desc) == len(source_ele_dtype), \
                            f"Length of most_similar_column_names, source_ele_desc, and source_ele_dtype should be the same. "
                        ## check if most_similar_column_names contains is non-empty
                        assert len(most_similar_column_names) > 0, f"No matching found for {target_col} in  category {category}"
                        assert len(source_info_filtered) == len(most_similar_column_names), \
                            f"Length of source_info_filtered and most_similar_column_names not the same for {target_col}."
                            
                        # ic(category, target_col, target_dtype, source_info_filtered, source_ele_dtype)
                        stat_col_mapping = {
                                'target_element': target_col,
                                'target_desc': target_desc,
                                'target_dtype': target_dtype,
                                'source_ele_recommended': most_similar_column_names,
                                'source_ele_desc': source_ele_desc
                                }
                        mappings.append(stat_col_mapping)
                        # ic(category, stat_col_mapping)
                    
        matching_dict.append(
            {'category_name': category,
            'mappings': mappings})

    if output_data_path!='':
        # save output as a json file
        with open(os.path.join(output_data_path, f"{fileprefix}_matching_dict.json"), 'w') as f:
            f.write(json.dumps(matching_dict, indent=4))
            

    return matching_dict


class TestGetMatching(unittest.TestCase):
    def test_get_matching(self):
        # Check if the folder already exists
        if not os.path.exists('data/test'):
            # Create the folder if it doesn't exist
            os.makedirs('data/test')
            
        # Create the input data
        source_data = {
        'Var Name': ['Population', 'GDP', 'Unemployment', 'Poverty', 'AreaDepIdx'],
        'Var Category': ['Demographics', 'Economy', 'Labor Market', 'Social', 'Social'],
        'Var Desc': ['Total population of the source', 'Gross Domestic Product', 'Unemployment rate', 'Poverty rate', 'Area Deprivation Index'],
        'Var Type': ['Numeric', 'Numeric', 'Numeric', 'Numeric', 'Numeric']
        }
        df = pd.DataFrame(source_data)
        # Save the dataframe to CSV
        df.to_csv('data/test/test_source_data_desc.csv', index=False)
        
        target_data = {
            'Variable name': ['Pop', 'GDP', 'Unemp', 'Pov', 'ADI'],
            'Variable category': ['Demographics', 'Economy', 'Labor Market', 'Social', 'Social'],
            'Variable description': ['Total population', 'Gross Domestic Product', 'Unemployment rate', 'Poverty rate', 'Area Deprivation Index'],
            'Variable data type': ['Numeric', 'Numeric', 'Numeric', 'Numeric', 'Numeric']
        }

        df = pd.DataFrame(target_data)

        # Save the dataframe to CSV
        df.to_csv('data/test/target_data_desc.csv', index=False)
        
        # Create the expected output
        expected_output = [{
            'category_name': 'Demographics',
            'mappings': [{
                'target_element': 'Pop',
                'target_desc': 'Total population',
                'target_dtype': 'Numeric',
                'source_ele_recommended': ['Population'],
                'source_ele_desc': ['Total population of the source'],
                }]},
            {'category_name': 'Economy',
            'mappings': [{
                'target_element': 'GDP',
                'target_desc': 'Gross Domestic Product',
                'target_dtype': 'Numeric',
                'source_ele_recommended': ['GDP'],
                'source_ele_desc': ['Gross Domestic Product'],      
                }]},

            {'category_name': 'Labor Market',
            'mappings': [{
                'target_element': 'Unemp',
                'target_desc': 'Unemployment rate',
                'target_dtype': 'Numeric',
                'source_ele_recommended': ['Unemployment'],
                'source_ele_desc': ['Unemployment rate'],
                }]},
            {'category_name': 'Social',
            'mappings': [{
                'target_element': 'Pov',
                'target_desc': 'Poverty rate',
                'target_dtype': 'Numeric',
                'source_ele_recommended': ['Poverty', 'AreaDepIdx'],
                'source_ele_desc': ['Poverty rate', 'Area Deprivation Index'],
                }, 
                         {
                'target_element': 'ADI',
                'target_desc': 'Area Deprivation Index',
                'target_dtype': 'Numeric',
                'source_ele_recommended': ['AreaDepIdx', 'Poverty'],
                'source_ele_desc': ['Area Deprivation Index', 'Poverty rate'],
                }]}]
        
        # Call the function to get the matching
        SOURCE_DATA_DESC_FILEPATH = 'data/test/test_source_data_desc.csv'
        input_variable_format = ['Var Name', 'Var Category', 'Var Desc', 'Var Type']
        
        self.input_data = {
            'source_data_desc_filepath': SOURCE_DATA_DESC_FILEPATH,
            'input_variable_format': input_variable_format,
            'fileprefix': 'test_',
            'target_data_desc_path': 'data/test/target_data_desc.csv',
        }
        output = get_matching(**self.input_data)

        ic(expected_output, output)
        # Assert the generated matching dictionary matches the expected results
        assert output == expected_output



def example_get_matching():
    import time
    GROUND_TRUTH_PATH = os.path.join('data', 'raw', 'state0_ground_truth.csv')  # Set this to None if there is no groundtruth
    source0_ground_truth = pd.read_csv(GROUND_TRUTH_PATH, header=0)

    start_time = time.time()
    example_output = get_matching(source_data_desc_filepath='data/raw/state0_data_desc.csv',
                input_variable_format=['Source element (State)', 'Source data element category', 'Source description', 'Source data type'],
                fileprefix='testsource_v3_',
                target_data_desc_path='data/raw/fda_data_desc.csv',
                output_data_path=os.path.join('data', 'processed'))
    end_time = time.time()
    runtime = end_time - start_time
    ic(example_output)

    print("Script completed in", runtime, "seconds")

if __name__ == '__main__':
    THIS_DIR = normpath(pathlib.Path(__file__).parent.resolve())
    PROJECT_DIR = normpath(
        join(THIS_DIR, "..")
    )  # pathlib.Path(__file__).parent.parent.parent.resolve()

    
    RAW_DIR = join(PROJECT_DIR, 'data', 'raw')

    example_get_matching()
    unittest.main()